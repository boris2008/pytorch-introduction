{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Metrics:\n",
    "    def __init__(self, num_classes):\n",
    "        self.num_classes = num_classes\n",
    "        self.loss = 0.0\n",
    "        self.accuracy = 0.0\n",
    "        self.precision = np.array([0.0 for _ in range(num_classes)])\n",
    "        self.recall = np.array([0.0 for _ in range(num_classes)])\n",
    "        self.f1 = np.array([0.0 for _ in range(num_classes)])\n",
    "\n",
    "    def update_loss(self, loss):\n",
    "        self.loss += loss\n",
    "\n",
    "    def update_metrics(self, targets, predictions):\n",
    "        self.accuracy += accuracy_score(targets, predictions)\n",
    "        prec_rec_f1 = precision_recall_fscore_support(\n",
    "            targets, predictions, labels=list(range(self.num_classes))\n",
    "        )\n",
    "\n",
    "        self.precision += prec_rec_f1[0]\n",
    "        self.recall += prec_rec_f1[1]\n",
    "        self.f1 += prec_rec_f1[2]\n",
    "\n",
    "    def compute_metrics(self, loader_size):\n",
    "        return (\n",
    "            self.loss / loader_size,\n",
    "            self.accuracy / loader_size,\n",
    "            self.precision / loader_size,\n",
    "            self.recall / loader_size,\n",
    "            self.f1 / loader_size,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNISTVanilla(Dataset):\n",
    "    def __init__(self, df):\n",
    "        self.df = df\n",
    "\n",
    "        self.transform = transforms.Compose(\n",
    "            [\n",
    "                transforms.Resize((224, 224)),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(\n",
    "                    torch.tensor([33.79 / 255.0 for _ in range(3)]),\n",
    "                    torch.tensor([79.17 / 255.0 for _ in range(3)]),\n",
    "                ),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.df.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "\n",
    "        img = Image.open(row[\"Image\"])\n",
    "        img = img.convert(\"RGB\")\n",
    "\n",
    "        return self.transform(img), torch.tensor([row[\"Label\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/mnist.csv\")\n",
    "df[\"Image\"] = df[\"Image\"].apply(lambda x: f\"../data/{x}\")\n",
    "df = df.head(100)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_vanilla = MNISTVanilla(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = DataLoader(mnist_vanilla, batch_size=batch_size, num_workers=8, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = df[\"Label\"].unique().shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Expects input img of Size([3, 224, 224])!\n",
    "model = models.resnet18(pretrained=True)\n",
    "model.fc = nn.Linear(model.fc.in_features, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(lr=0.001, params=model.parameters())\n",
    "loss_fn = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = [None] * num_epochs\n",
    "for idx, epoch in enumerate(range(num_epochs)):\n",
    "    metrics = Metrics(num_classes)\n",
    "    model.train()\n",
    "    for X, y in loader:\n",
    "        # Size([32, 1]) -> Size([32]), necessary for CrossEntropyLoss\n",
    "        # - See https://pytorch.org/docs/master/generated/torch.nn.CrossEntropyLoss.html#torch.nn.CrossEntropyLoss\n",
    "        targets = y.squeeze(1)\n",
    "\n",
    "        outputs = model(X)\n",
    "        loss = loss_fn(outputs, targets)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        metrics.update_loss(loss.clone().detach().item())\n",
    "        predictions = outputs.clone().detach().argmax(dim=1)\n",
    "        metrics.update_metrics(targets, predictions)\n",
    "\n",
    "    t_loss, t_acc, t_prec, t_rec, t_f1 = metrics.compute_metrics(len(loader))\n",
    "    print(f\"Epoch: {epoch}\")\n",
    "    print(f\"Loss: {t_loss}\")\n",
    "    losses[idx] = t_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(list(range(num_epochs)), losses)\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(\n",
    "    {\n",
    "        \"model_state_dict\": model.state_dict(),\n",
    "        \"optimizer_state_dict\": optimizer.state_dict(),\n",
    "        \"train_loss\": t_loss,\n",
    "        \"train_accuracy\": t_acc,\n",
    "        \"train_precision\": t_prec,\n",
    "        \"train_recall\": t_rec,\n",
    "        \"train_f1\": t_f1,\n",
    "    },\n",
    "    \"resnet18-transfer-epoch-4.tar\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_acc"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
